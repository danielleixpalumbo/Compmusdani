---
title: "How does today's Hip Hop differ from 90's Hip Hop?"
author: "Daniel Leix Palumbo"
date: "22 February 2019"
output: 
   flexdashboard::flex_dashboard:
       storyboard: true
       theme: lumen
       vertical_layout: scroll 
---

```{r, cache = FALSE}

devtools::install_github('charlie86/spotifyr')
devtools::install_github('jaburgoyne/compmus')

library(tidyverse)
library(spotifyr)
library(plotly)
library(compmus)
library(rsample)
library(recipes)
library(parsnip)
library(yardstick)

# Spotify access variables 

Sys.setenv(SPOTIFY_CLIENT_ID = '8e7bf977224b414d8e6b255352c63b5a')
Sys.setenv(SPOTIFY_CLIENT_SECRET = '1b2f3f287a724da8b6ed562dbf4d99e1')

access_token <- get_spotify_access_token()
```

### Introduction 

![](http://townsquare.media/site/812/files/2018/01/xxx-tentacion-tupac.jpg)

*** 

How does hip-hop from the 1990s differ from hip-hop today? 

With the aim to answer to this question, It has been decided to look for reliable playlists on Spotify through which it could have been gained valuable insight into the most remarkable differences within and between the two time periods. In order to do so, two playlists have been chosen as corpus of data, namely "Hip Hop 90s" from "Hip Hop Heroes" and "Hip Hop 2019: Top100 Rap HITS 2019 / Rap 2019 New Hip Hop Songs" from "Filtr Espana", and have been analysed by comparing their key features. The two playlists contain respectively 64 and 100 tracks. 
These two playlists were chosen since they presented similar features in terms of number of followers and number of tracks, and also they contained tracks from the most famous and representative artists of the two time periods. 

### A closer look at the two playlists: is Hip Hop become faster in 20 years?  

```{r}

HipHop_90s <- get_playlist_audio_features('hhheroes', '5fWeZI5FLdUkowl4qaglPi')
HipHop_today <- get_playlist_audio_features('mejoresplaylistsspotify','0OtdLZ5JVyqB4Zp8aylECe')

HipHops <-
  HipHop_90s %>% mutate(playlist = "HipHop90") %>%
  bind_rows(HipHop_today %>% mutate(playlist = "HipHopToday"))

# Make our own visualisation 
HipHop_label_Around<- tibble(
    label = "Around the Way Girl",
    playlist = "HipHop90",
    speechiness = 0.356, 
    tempo = 202.084)
HipHop_label_Party<- tibble(
    label =  "Party Up",
    playlist = "HipHop90",
    speechiness = 0.347,
    tempo =  201.936)
HipHopScatterplot <-    
HipHops %>%
  ggplot(aes(x = speechiness, y = tempo, color = mode, size = energy, label = track_name)) +
   geom_point(alpha = 0.8)+
   facet_wrap(~ playlist)+
   geom_text (aes( x = speechiness,y = tempo, label = label), colour = "black", size = 3, data = HipHop_label_Around, hjust = "left", vjust = "up", nudge_y = 13)+
   geom_text (aes( x = speechiness,y = tempo, label = label), colour = "black", size = 3, data = HipHop_label_Party, hjust = "left", vjust = "bottom", nudge_y = 20)+
   geom_jitter(width = 0.00001, height = 0.00001)+
   theme_light() +              
   labs( x = "Speechines", y = "Tempo", colour = "Mode")+
   scale_y_continuous(limits = c(0, 240), breaks = c(0, 50, 100, 150, 200), minor_breaks = NULL)+
  scale_x_continuous(limits = c(0, 0.5), breaks = c(0, 0.1,  0.2,  0.3,  0.4,  0.5), minor_breaks = NULL)+
  scale_size_continuous(trans = "exp", guide = "none")
ggplotly(HipHopScatterplot)

```

*** 

After that the audio features from both playlists have been gathered using "spotifyr", it has been decided to represent the two data sets in two different scatterplots with speechiness on the x-axis and tempo on the y-axis. As a result, it can be observed on the scatterplots that overall Hip-Hop got significantly faster in 20 years, since most of the 90's tracks are below the 100 BPM level while most of the today's tracks cover the range from 100 BPM to 175. In addition, from the scatterplot can be observed also a couple of outliers, which are two today's hip hop songs, namely "Around the Way Girl" and "Party Up", that surprisingly are above the 200 BPM, representing the fastest tracks of both data sets. However, after I listened to both the songs, it must be said that in this case Spotify's tempo detection was far from the truth. 

The values of speechiness are slightly higher for the 90's tracks, demonstrating a little decrease of the use of spoken words in today's tracks. But here too, there's an outlier represented by today's track "Endless Summer Freestyle", which has the highest amount of spoken words with the value of 0.4630. In addition, the average danceability and energy for both playlists have been obtained but those haven't shown any remarkable difference for these features, the values of which are marginally higher in 90's tracks. However, the energy of the tracks has been mapped to the size of the dots, in order to make more information visible. 

Finally, as it can be observed in the scatterplot the dots are coloured by "mode", but in both playlist it has been found a certain balance between songs in major and in minor and there's no remarkable trend to be noticed. The increasing acceleration of today's Hip Hop tracks appear to be at the moment the most interesting finding.

### Use of the Random Forest classifier in order to confirm the project's first findings

```{r}
HipHop_90s <-
    get_playlist_audio_features('hhheroes', '5fWeZI5FLdUkowl4qaglPi') %>% 
    slice(1:20) %>% 
    add_audio_analysis
HipHop_today <-
    get_playlist_audio_features('mejoresplaylistsspotify','0OtdLZ5JVyqB4Zp8aylECe') %>% 
    slice(1:20) %>% 
    add_audio_analysis
```

```{r}
HipHop <- 
    HipHop_90s %>% mutate(playlist = "90's Hip Hop") %>% 
    bind_rows(
        HipHop_today %>% mutate(playlist = "Today's Hip Hop")) %>% 
    mutate(playlist = factor(playlist)) %>% 
    mutate(
        segments = 
            map2(segments, key, compmus_c_transpose)) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan'),
        timbre =
            map(
                segments,
                compmus_summarise, timbre,
                method = 'mean')) %>% 
    mutate(pitches = map(pitches, compmus_normalise, 'clr')) %>% 
    mutate_at(vars(pitches, timbre), map, bind_rows) %>% 
    unnest(pitches, timbre)
```

```{r}
HipHop_class <- 
    recipe(playlist ~
               danceability +
               energy +
               loudness +
               speechiness +
               acousticness +
               instrumentalness +
               liveness +
               valence +
               tempo +
               duration_ms +
               C + `C#|Db` + D + `D#|Eb` +
               E + `F` + `F#|Gb` + G +
               `G#|Ab` + A + `A#|Bb` + B +
               c01 + c02 + c03 + c04 + c05 + c06 +
               c07 + c08 + c09 + c10 + c11 + c12,
           data = HipHop) %>% 
    step_center(all_predictors()) %>%
    step_scale(all_predictors()) %>%
    # step_range(all_predictors()) %>% 
    prep(HipHop) %>% 
    juice
```

```{r}
HipHop_cv <- HipHop_class %>% vfold_cv(5)
```

```{r}
HipHop_forest <- rand_forest() %>% set_engine('randomForest')
predict_forest <- function(split)
    fit(HipHop_forest, playlist ~ ., data = analysis(split)) %>% 
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))
```

```{r}
HipHop_cv %>% 
    mutate(pred = map(splits, predict_forest)) %>% 
    unnest(pred) %>% 
    metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)
```

```{r}
HipHop_class %>% 
    fit(HipHop_forest, playlist ~ ., data = .) %>% 
    pluck('fit') %>% 
    randomForest::varImpPlot()
```

***

By using the random forest classifier, the project aims to see if the results previously dipslayed could be considered solid in order to anwer to the research question of this portfolio. As it can be seen clearly by the plot, which shows the best-quality ranking of feature importance, tempo and speechiness are confirmed as the most important features of our playlists along with timbre, especially in its components 7 and 8 which will be better analysed later.

### The use of samples in 90's Hip-Hop, a closer look to "He got game"

```{r}
HeGotGame <- 
    get_tidy_audio_analysis('7aRGb3vZGMLNpK2PEdUjdA') %>% 
    select(segments) %>% unnest(segments) %>% 
    select(start, duration, pitches)
ForWhat <- 
    get_tidy_audio_analysis('1qRA5BS78u3gME0loMl9AA') %>% 
    select(segments) %>% unnest(segments) %>% 
    select(start, duration, pitches)
TodayHipHop_dist <- 
    compmus_long_distance(
    HeGotGame %>% mutate(pitches = map(pitches, compmus_normalise, 'manhattan')),
    ForWhat %>% mutate(pitches = map(pitches, compmus_normalise, 'manhattan')),
    feature = pitches,
    method = 'aitchison')
```


```{r}
TodayHipHop <- 
   TodayHipHop_dist %>% 
    mutate(
        HeGotGame = xstart + xduration / 2, 
        ForWhat = ystart + yduration / 2) %>% 
    ggplot(
        aes(
            x = HeGotGame,
            y = ForWhat,
            fill = d)) + 
    geom_tile(aes(width = xduration, height = yduration)) +
    coord_fixed() +
    scale_x_continuous(
        breaks = c(0, 59, 79, 128, 148, 158, 197, 217, 286), 
        labels = 
            c(
                'Verse',
                'Chorus',
                'Verse2',
                'Chorus2',
                'Bridge',
                'OriginalTrackChorus',
                'Special',
                'FinalVerse',
                ''),
        ) +
    scale_y_continuous(
        breaks = c(0, 28, 34, 63, 69, 78, 97, 102, 112, 131, 153), 
        labels = 
            c(
                'Verse',
                'Chorus',
                'Verse2',
                'Chorus2',
                'Bridge',
                'Verse3',
                'Chorus3',
                'Bridge2' ,
                'Special' ,
                'Chorus4' , 
              ''),
        ) +
    scale_fill_viridis_c(option = 'E', guide = "none") +
    theme_classic() + 
    theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
    labs(x = 'He Got Game', y = 'For What it s Worth')
TodayHipHop
```

***

In order to fully define what are the sonic differences between 90's and today's Hip Hop it is necessary to take in account how the use of sampling has changed between these two time frames. In fact, sampling represents one of the most common artistic practices performed by Hip Hop producers during the composition of a track, by means of which a portion or sample from another sound recording is reused and manipulated. 

To do this, it has been decided to look to what extent two of the most representative Hip Hop tracks from the two different time frames, which make use of samples coming from other sound recordings, differ from the original tracks. The differences between the Hip Hop tracks and the original songs is indicated by showing their alignments with the dynamic time-warping techniques, using the Aitchison distance between chroma features. 

The famous Hip Hop track "He Got Game" by Public Enemy from the 90's is shown as reference point for this comparison in its alignment with the other real classic "For What it's Worth" by Buffalo Springfield, the main riff of which (the well known guitar harmonics played by Neil Young) has been sampled in fact by Public Enemy and constitutes the skeleton of the Hip Hop track. The sample in "He Got Game" has been not manipulated at all and as a result the guitar riff from Buffalo Springfield plays at the same speed in both songs, which become really different only when there's the chorus in "For What it's Worth". Therefore the two songs are perfectly aligned only when the verse of "For What it's Worth" is playing, as it is basically omnipresent in the structure of "He Got Game".

```{r}
TodayHipHop_hist <- 
    TodayHipHop_dist %>% 
    ggplot(aes(x = d)) +
    geom_histogram(binwidth = 0.5) +
    theme_classic() + 
    theme(
        axis.line.y = element_blank(), 
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank()) +
    scale_x_continuous(breaks = c(0.7, 4.4, 5.5, 6.8, 14.2)) +
    labs(x = 'Aitchison Distance', y = '')
ggsave("compmus-HeGotGame.png", TodayHipHop_hist, width = 3, height = 2, dpi = 'screen')
```

![](compmus-HeGotGame.png)

### How is changed the use of samples in today's Hip-Hop? Let's take "Endless Summer Freestyle" as benchmark for our comparison

```{r}
Endless <- 
    get_tidy_audio_analysis('6yxYCurtUz8MOAgWGxlAzP') %>% 
    select(segments) %>% unnest(segments) %>% 
    select(start, duration, pitches)
Neky_Hokey <- 
    get_tidy_audio_analysis('0DelTitHNIJ8uUBpGpT0Hk') %>% 
    select(segments) %>% unnest(segments) %>% 
    select(start, duration, pitches)
OldHipHop_dist <- 
    compmus_long_distance(
    Endless %>% mutate(pitches = map(pitches, compmus_normalise, 'manhattan')),
    Neky_Hokey %>% mutate(pitches = map(pitches, compmus_normalise, 'manhattan')),
    feature = pitches,
    method = 'aitchison')
```


```{r}
OldHipHop <- 
    OldHipHop_dist %>% 
    mutate(
        Endless = xstart + xduration / 2, 
        Neky_Hokey = ystart + yduration / 2) %>% 
    ggplot(
        aes(
            x = Endless,
            y = Neky_Hokey,
            fill = d)) + 
    geom_tile(aes(width = xduration, height = yduration)) +
    coord_fixed() +
    scale_x_continuous(
        breaks = c(0, 14, 215, 237), 
        labels = 
            c(
                'Intro',
                'Verse',
                'Outro',
                ''),
        ) +
    scale_y_continuous(
        breaks = c(0, 7,  40, 56, 92, 103, 125, 141), 
        labels = 
            c(
                'Intro',
                'Chorus',
                'Verse',
                'Solo',
                'Verse2',
                'Chorus2',
                'Outro',
              ''),
        ) +
    scale_fill_viridis_c(option = 'E', guide = "none") +
    theme_classic() + 
    theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
    labs(x = 'Endless Summer Freestyle', y = 'Neki-Hokey')
OldHipHop
```

***

As it has been previously analysed the use of sampling in 90's Hip Hop with "He got Game" by Public Enemy, with the same process it can be observed how this foundational artistic practice has been changed in 25/30 years by looking at the today's Hip Hop song "Endless Summer Freestyle" by G-Eazy ft. YG, the backing track of which is a sample by the song "Neki-Hokey" by the 50's american vocal group "The Cleftones". 

In this case there is almost no consistency in the relationship between the songs, as the original sample by "The Cleftones" is strongly manipulated in "Endless Summer Freestyle", in which the sample's pitch is lowered and consequently it sounds much slower than the original one present in the verse of "Neki-Hokey". In addition, the structure of "Neki-Hokey" is much more complex than the one of "Endless Summer Freestyle" (in which basically the sample is continuosly repeated for the entire track), showing different sections during the song and making therefore any attempt of alignment almost impossible. 

This comparison made through the incorporation of Spotify's chroma features and the alignment of Hip Hop tracks with their respective original sampled tracks showed that the use of sampling has changed a lot in these decades, indicating that the original samples in today's Hip Hop production are subject to much stronger manipulations in terms of pitch shifting, etc.  

```{r}
OldHipHop_hist <- 
    OldHipHop_dist %>% 
    ggplot(aes(x = d)) +
    geom_histogram(binwidth = 0.5) +
    theme_classic() + 
    theme(
        axis.line.y = element_blank(), 
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank()) +
    scale_x_continuous(breaks = c(0.7, 4.4, 5.5, 6.8, 14.2)) +
    labs(x = 'Aitchison Distance', y = '')
ggsave("compmus-Endless.png", OldHipHop_hist, width = 3, height = 2, dpi = 'screen')
```

![](compmus-Endless.png)


### Understanding of the structure of "The choise is yours" through an analysis of chroma and timbre features

```{r}
BlackSheep <- 
    get_tidy_audio_analysis('0cbodmgjBx4IVPOIyl3F4b') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'rms', norm = 'euclidean')) %>% 
    mutate(
        timbre = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'rms'))
BlackSheepplot <- 
    bind_rows(
        BlackSheep %>% compmus_self_similarity(pitches, 'angular') %>% mutate(d = d / max(d), type = "Chroma"),
        BlackSheep %>% compmus_self_similarity(timbre, 'cosine') %>% mutate(d = d / max(d), type = "Timbre")) %>% 
    ggplot(
        aes(
            x = xstart + xduration / 5, 
            width = xduration,
            y = ystart + yduration / 5,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    facet_wrap(~ type) +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '')
ggplotly(BlackSheepplot)
```

***

In this 4th section of the project the structure of the 90s Hip Hop true classic "The Choise is yours" by Black Sheep is analysed by comparing the chroma-based and timbre-based self-similarity matrices. 
As Hip Hop tracks tend to be pretty homogeneous in their structure, also "The Choise is yours" follows the same trend, by fundamentally showing two main sections in its structural layout, which could be named in this case as kind of verse and chorus. The alternation of the two sections is not well visible in the chroma-based matrix, as there are no great variations in terms of pitches across the entire song. 
In contrast, the timbre-based matrix makes this alternation much more visible, as the switch to the different part of the song is highlighted by the presence or the absence of certain instruments: the verse is charachterised by the well-known double bass riff, while in the chorus only voices and drums are present.

### Chordogram of the true classic "Changes" by 2pac

```{r}
circshift <- function(v, n) {if (n == 0) v else c(tail(v, n), head(v, -n))}
                                    
    # C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B 
major_chord <- 
    c(1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <- 
    c(1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <- 
    c(1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <- 
    c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
    c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
    tribble(
        ~name  , ~template,
        'Gb:7'  , circshift(seventh_chord,  6),
        'Gb:maj', circshift(major_chord,    6),
        'Bb:min', circshift(minor_chord,   10),
        'Db:maj', circshift(major_chord,    1),
        'F:min' , circshift(minor_chord,    5),
        'Ab:7'  , circshift(seventh_chord,  8),
        'Ab:maj', circshift(major_chord,    8),
        'C:min' , circshift(minor_chord,    0),
        'Eb:7'  , circshift(seventh_chord,  3),
        'Eb:maj', circshift(major_chord,    3),
        'G:min' , circshift(minor_chord,    7),
        'Bb:7'  , circshift(seventh_chord, 10),
        'Bb:maj', circshift(major_chord,   10),
        'D:min' , circshift(minor_chord,    2),
        'F:7'   , circshift(seventh_chord,  5),
        'F:maj' , circshift(major_chord,    5),
        'A:min' , circshift(minor_chord,    9),
        'C:7'   , circshift(seventh_chord,  0),
        'C:maj' , circshift(major_chord,    0),
        'E:min' , circshift(minor_chord,    4),
        'G:7'   , circshift(seventh_chord,  7),
        'G:maj' , circshift(major_chord,    7),
        'B:min' , circshift(minor_chord,   11),
        'D:7'   , circshift(seventh_chord,  2),
        'D:maj' , circshift(major_chord,    2),
        'F#:min', circshift(minor_chord,    6),
        'A:7'   , circshift(seventh_chord,  9),
        'A:maj' , circshift(major_chord,    9),
        'C#:min', circshift(minor_chord,    1),
        'E:7'   , circshift(seventh_chord,  4),
        'E:maj' , circshift(major_chord,    4),
        'G#:min', circshift(minor_chord,    8),
        'B:7'   , circshift(seventh_chord, 11),
        'B:maj' , circshift(major_chord,   11),
        'D#:min', circshift(minor_chord,    3),
)

key_templates <-
    tribble(
        ~name    , ~template,
        'Gb:maj', circshift(major_key,  6),
        'Bb:min', circshift(minor_key, 10),
        'Db:maj', circshift(major_key,  1),
        'F:min' , circshift(minor_key,  5),
        'Ab:maj', circshift(major_key,  8),
        'C:min' , circshift(minor_key,  0),
        'Eb:maj', circshift(major_key,  3),
        'G:min' , circshift(minor_key,  7),
        'Bb:maj', circshift(major_key, 10),
        'D:min' , circshift(minor_key,  2),
        'F:maj' , circshift(major_key,  5),
        'A:min' , circshift(minor_key,  9),
        'C:maj' , circshift(major_key,  0),
        'E:min' , circshift(minor_key,  4),
        'G:maj' , circshift(major_key,  7),
        'B:min' , circshift(minor_key, 11),
        'D:maj' , circshift(major_key,  2),
        'F#:min', circshift(minor_key,  6),
        'A:maj' , circshift(major_key,  9),
        'C#:min', circshift(minor_key,  1),
        'E:maj' , circshift(major_key,  4),
        'G#:min', circshift(minor_key,  8),
        'B:maj' , circshift(major_key, 11),
        'D#:min', circshift(minor_key,  3))
```

```{r}
Tupac <- 
    get_tidy_audio_analysis('3Wyc7M8twhxeyaC51BcQYb') %>% 
    compmus_align(beats, segments) %>% 
    select(beats) %>% unnest(beats) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan'))
    
```

```{r}
Tupac %>% 
    compmus_match_pitch_template(chord_templates, 'euclidean', 'manhattan') %>% 
    ggplot(
        aes(x = start + duration / 2, width = duration, y = name, fill = d)) +
    geom_tile() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_minimal() +
    labs(x = 'Time (s)', y = '')

```

***

As last tab of the project, it has been decided to make a chordogram of a 90's Hip Hop true classic, namely "Changes" by 2pac, who was one of the most representative artist of the time. 
The song is characterised by the well-known series of piano chords and this tab of the project aims to show how these chords are detected by the chordogram, in which the track is summarised at the level of beats. 

There are two different series of piano chords that are present during the entire track, which are those of the verse (that move through the following chords: A minor, E minor, D major, C major, G major, D major, C major) and those of the chorus (A minor, G major and C major). These two are generally correctly estimated, but as it can be noticed there's always high spillage into related chords (this is even more evident when the C major chord is played during the verse) and consequently the chord progression does not appear so clearly in the here presented chordogram. 

